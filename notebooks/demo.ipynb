{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5eaba83",
   "metadata": {},
   "source": [
    "# üåç Adaptive Travel Recommendation System - Interactive Demo\n",
    "\n",
    "This notebook provides an interactive demonstration of three reinforcement learning algorithms for travel recommendations:\n",
    "- **Epsilon-Greedy**\n",
    "- **LinUCB (Contextual Bandit)**\n",
    "- **Thompson Sampling**\n",
    "\n",
    "You can interact with each model and see how they learn from your feedback!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82400eca",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4cf0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import agent classes from models module\n",
    "from models.agents import EpsilonGreedyAgent, LinUCBAgent, ContextualThompsonSampling\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74f0e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9588fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 20 user profiles\n",
      "‚úÖ Loaded 141 travel destinations\n",
      "‚úÖ Feature types: 12\n"
     ]
    }
   ],
   "source": [
    "# Load user profiles\n",
    "df_users = pd.read_csv('../data/gen/user_profiles.csv')\n",
    "feature_columns = [col for col in df_users.columns if col != 'user_id']\n",
    "\n",
    "# Convert to user profile dictionaries\n",
    "user_profiles = []\n",
    "for _, row in df_users.iterrows():\n",
    "    user_id = int(row['user_id'])\n",
    "    prefs = {col: row[col] for col in feature_columns}\n",
    "    user_profiles.append({\"id\": user_id, \"prefs\": prefs})\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(user_profiles)} user profiles\")\n",
    "\n",
    "# Load places from dataset\n",
    "df_places = pd.read_csv('../data/final_dataset.csv')\n",
    "places = []\n",
    "for _, row in df_places.iterrows():\n",
    "    keywords = row['Keywords'].split(', ')\n",
    "    primary_type = keywords[0] if keywords else 'du l·ªãch'\n",
    "    places.append({\n",
    "        \"name\": row['Location Name'],\n",
    "        \"type\": primary_type,\n",
    "        \"keywords\": keywords,\n",
    "        \"rating\": row['Rating']\n",
    "    })\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(places)} travel destinations\")\n",
    "print(f\"‚úÖ Feature types: {len(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380cab5b",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0339c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_to_vector(user):\n",
    "    \"\"\"Convert user preferences to vector\"\"\"\n",
    "    return np.array([user[\"prefs\"].get(col, 0) for col in feature_columns])\n",
    "\n",
    "def simulate_reward(user, place):\n",
    "    \"\"\"Simulate reward based on user preferences and place rating\"\"\"\n",
    "    pref_score = user[\"prefs\"].get(place[\"type\"], 0)\n",
    "    place_r = np.clip(place.get(\"rating\", 3.0) / 5.0, 0, 1)\n",
    "    utility = 0.7 * pref_score + 0.3 * place_r\n",
    "    prob = np.clip(utility + np.random.normal(0, 0.05), 0, 1)\n",
    "    rating = int(np.floor(prob * 5)) + 1\n",
    "    return max(1, min(5, rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0256193b",
   "metadata": {},
   "source": [
    "## Load or Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebef5d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pre-trained models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Try to load pre-trained models\n",
    "model_dir = '../saved_models'\n",
    "models_loaded = False\n",
    "\n",
    "try:\n",
    "    with open(f'{model_dir}/epsilon_greedy.pkl', 'rb') as f:\n",
    "        agent_egreedy = pickle.load(f)\n",
    "    with open(f'{model_dir}/linucb.pkl', 'rb') as f:\n",
    "        agent_linucb = pickle.load(f)\n",
    "    with open(f'{model_dir}/thompson_sampling.pkl', 'rb') as f:\n",
    "        agent_ts = pickle.load(f)\n",
    "    \n",
    "    print(\"‚úÖ Pre-trained models loaded successfully!\")\n",
    "    models_loaded = True\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  Pre-trained models not found. Please run train.ipynb first.\")\n",
    "    print(\"Creating new models with minimal training...\")\n",
    "    \n",
    "    # Quick training function\n",
    "    def quick_train(agent, agent_type, n_rounds=500):\n",
    "        for _ in range(n_rounds):\n",
    "            user = random.choice(user_profiles)\n",
    "            \n",
    "            if agent_type == \"egreedy\":\n",
    "                arm = agent.select_arm()\n",
    "                rating = simulate_reward(user, places[arm])\n",
    "                reward = 1 + (rating - 1) / 4\n",
    "                agent.update(arm, reward)\n",
    "                \n",
    "            else:  # contextual agents\n",
    "                x = context_to_vector(user)\n",
    "                ranked, _ = agent.select_arm(x)\n",
    "                arm = random.choice(ranked[:3])\n",
    "                rating = simulate_reward(user, places[arm])\n",
    "                reward = 1 + (rating - 1) / 4\n",
    "                agent.update(arm, x, reward)\n",
    "    \n",
    "    # Initialize and quick train\n",
    "    agent_egreedy = EpsilonGreedyAgent(n_arms=len(places), epsilon=0.2)\n",
    "    agent_linucb = LinUCBAgent(n_arms=len(places), n_features=len(feature_columns), alpha=0.1)\n",
    "    agent_ts = ContextualThompsonSampling(n_arms=len(places), d=len(feature_columns), alpha=0.1)\n",
    "    \n",
    "    print(\"Training Epsilon-Greedy...\")\n",
    "    quick_train(agent_egreedy, \"egreedy\", 500)\n",
    "    print(\"Training LinUCB...\")\n",
    "    quick_train(agent_linucb, \"linucb\", 500)\n",
    "    print(\"Training Thompson Sampling...\")\n",
    "    quick_train(agent_ts, \"ts\", 500)\n",
    "    \n",
    "    print(\"‚úÖ Models trained with 500 rounds each!\")\n",
    "    models_loaded = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a4a0b",
   "metadata": {},
   "source": [
    "## Interactive Recommendation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f117fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_recommendation_egreedy(agent):\n",
    "    \"\"\"Interactive recommendation using Epsilon-Greedy\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üéØ EPSILON-GREEDY TRAVEL RECOMMENDER\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    while True:\n",
    "        # Get top-3 recommendations\n",
    "        ranked = np.argsort(agent.values)[::-1][:3]\n",
    "        \n",
    "        print(\"\\n‚úàÔ∏è  Top 3 Recommendations for You:\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, idx in enumerate(ranked):\n",
    "            print(f\"   {i+1}. {places[idx]['name']:30s} ({places[idx]['type']:15s}) | Score: {agent.values[idx]:.3f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Get user input\n",
    "        clicks = input(\"\\nüëÜ Click on recommendation (1-3) or 'q' to quit: \")\n",
    "        if clicks.lower() == 'q':\n",
    "            print(\"\\nüëã Thank you for using the Travel Recommender!\")\n",
    "            break\n",
    "        \n",
    "        # Process clicks\n",
    "        clicked_arms = []\n",
    "        for c in clicks.split():\n",
    "            try:\n",
    "                idx = int(c) - 1\n",
    "                if 0 <= idx < len(ranked):\n",
    "                    clicked_arms.append(ranked[idx])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not clicked_arms:\n",
    "            print(\"‚ö†Ô∏è  No valid selection. Please try again.\")\n",
    "            continue\n",
    "        \n",
    "        # Get ratings and update\n",
    "        for arm in ranked:\n",
    "            if arm in clicked_arms:\n",
    "                try:\n",
    "                    rating = float(input(f\"‚≠ê Rate '{places[arm]['name']}' (0-1): \"))\n",
    "                    rating = np.clip(rating, 0, 1)\n",
    "                except:\n",
    "                    rating = 1\n",
    "                agent.update(arm, rating)\n",
    "            else:\n",
    "                agent.update(arm, -0.1)\n",
    "        \n",
    "        print(\"\\n‚úÖ Model updated with your feedback!\")\n",
    "        clear_output(wait=True)\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üéØ EPSILON-GREEDY TRAVEL RECOMMENDER\")\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f9b6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_recommendation_linucb(agent):\n",
    "    \"\"\"Interactive recommendation using LinUCB\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üéØ LinUCB CONTEXTUAL TRAVEL RECOMMENDER\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    while True:\n",
    "        # Get user ID\n",
    "        user_input = input(\"\\nüë§ Enter user ID (0-19) or 'q' to quit: \")\n",
    "        if user_input.lower() == 'q':\n",
    "            print(\"\\nüëã Thank you for using the Travel Recommender!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            user_id = int(user_input)\n",
    "            if user_id < 0 or user_id >= len(user_profiles):\n",
    "                print(\"‚ö†Ô∏è  Invalid user ID! Please enter a number between 0 and 19.\")\n",
    "                continue\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Invalid input!\")\n",
    "            continue\n",
    "        \n",
    "        user = user_profiles[user_id]\n",
    "        x = context_to_vector(user)\n",
    "        \n",
    "        # Get top-3 recommendations with scores\n",
    "        scores = []\n",
    "        for arm in range(len(places)):\n",
    "            A_inv = np.linalg.inv(agent.A[arm])\n",
    "            theta = A_inv @ agent.b[arm]\n",
    "            score = theta @ x + agent.alpha * np.sqrt(x @ A_inv @ x)\n",
    "            scores.append(score)\n",
    "        \n",
    "        ranked = np.argsort(scores)[::-1][:3]\n",
    "        \n",
    "        print(f\"\\n‚úàÔ∏è  Top 3 Recommendations for User {user_id}:\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, idx in enumerate(ranked):\n",
    "            print(f\"   {i+1}. {places[idx]['name']:30s} ({places[idx]['type']:15s}) | Score: {scores[idx]:.3f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Get clicks\n",
    "        clicks = input(\"\\nüëÜ Click on recommendation (1-3) or 'q' to quit: \")\n",
    "        if clicks.lower() == 'q':\n",
    "            print(\"\\nüëã Thank you for using the Travel Recommender!\")\n",
    "            break\n",
    "        \n",
    "        clicked_arms = []\n",
    "        for c in clicks.split():\n",
    "            try:\n",
    "                idx = int(c) - 1\n",
    "                if 0 <= idx < len(ranked):\n",
    "                    clicked_arms.append(ranked[idx])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not clicked_arms:\n",
    "            print(\"‚ö†Ô∏è  No valid selection. Please try again.\")\n",
    "            continue\n",
    "        \n",
    "        # Get ratings and update\n",
    "        for arm in ranked:\n",
    "            if arm in clicked_arms:\n",
    "                try:\n",
    "                    rating = float(input(f\"‚≠ê Rate '{places[arm]['name']}' (0-1): \"))\n",
    "                    rating = np.clip(rating, 0, 1)\n",
    "                except:\n",
    "                    rating = 1\n",
    "                agent.update(arm, x, rating)\n",
    "            else:\n",
    "                agent.update(arm, x, -0.1)\n",
    "        \n",
    "        print(\"\\n‚úÖ Model updated with your feedback!\")\n",
    "        clear_output(wait=True)\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üéØ LinUCB CONTEXTUAL TRAVEL RECOMMENDER\")\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee0da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_recommendation_ts(agent):\n",
    "    \"\"\"Interactive recommendation using Thompson Sampling\"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üéØ THOMPSON SAMPLING TRAVEL RECOMMENDER\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    while True:\n",
    "        # Get user ID\n",
    "        user_input = input(\"\\nüë§ Enter user ID (0-19) or 'q' to quit: \")\n",
    "        if user_input.lower() == 'q':\n",
    "            print(\"\\nüëã Thank you for using the Travel Recommender!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            user_id = int(user_input)\n",
    "            if user_id < 0 or user_id >= len(user_profiles):\n",
    "                print(\"‚ö†Ô∏è  Invalid user ID! Please enter a number between 0 and 19.\")\n",
    "                continue\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Invalid input!\")\n",
    "            continue\n",
    "        \n",
    "        user = user_profiles[user_id]\n",
    "        x = context_to_vector(user)\n",
    "        \n",
    "        # Get top-3 recommendations using Thompson Sampling\n",
    "        sampled_rewards = []\n",
    "        for arm in range(agent.n_arms):\n",
    "            B_inv = np.linalg.inv(agent.B[arm])\n",
    "            mu_hat = B_inv @ agent.f[arm]\n",
    "            theta_sample = np.random.multivariate_normal(mu_hat, agent.alpha**2 * B_inv)\n",
    "            sampled_rewards.append(theta_sample @ x)\n",
    "        \n",
    "        ranked = np.argsort(sampled_rewards)[::-1][:3]\n",
    "        \n",
    "        print(f\"\\n‚úàÔ∏è  Top 3 Recommendations for User {user_id}:\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, idx in enumerate(ranked):\n",
    "            print(f\"   {i+1}. {places[idx]['name']:30s} ({places[idx]['type']:15s}) | Score: {sampled_rewards[idx]:.3f}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Get clicks\n",
    "        clicks = input(\"\\nüëÜ Click on recommendation (1-3) or 'q' to quit: \")\n",
    "        if clicks.lower() == 'q':\n",
    "            print(\"\\nüëã Thank you for using the Travel Recommender!\")\n",
    "            break\n",
    "        \n",
    "        clicked_arms = []\n",
    "        for c in clicks.split():\n",
    "            try:\n",
    "                idx = int(c) - 1\n",
    "                if 0 <= idx < len(ranked):\n",
    "                    clicked_arms.append(ranked[idx])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not clicked_arms:\n",
    "            print(\"‚ö†Ô∏è  No valid selection. Please try again.\")\n",
    "            continue\n",
    "        \n",
    "        # Get ratings and update\n",
    "        for arm in ranked:\n",
    "            if arm in clicked_arms:\n",
    "                try:\n",
    "                    rating = float(input(f\"‚≠ê Rate '{places[arm]['name']}' (0-1): \"))\n",
    "                    rating = np.clip(rating, 0, 1)\n",
    "                except:\n",
    "                    rating = 1\n",
    "                agent.update(arm, x, rating)\n",
    "            else:\n",
    "                agent.update(arm, x, 0)\n",
    "        \n",
    "        print(\"\\n‚úÖ Model updated with your feedback!\")\n",
    "        clear_output(wait=True)\n",
    "        print(\"=\" * 70)\n",
    "        print(\"üéØ THOMPSON SAMPLING TRAVEL RECOMMENDER\")\n",
    "        print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba65e72",
   "metadata": {},
   "source": [
    "## üéÆ Try the Demos!\n",
    "\n",
    "Choose one of the models below to interact with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c4136",
   "metadata": {},
   "source": [
    "### Demo 1: Epsilon-Greedy\n",
    "\n",
    "This model uses a simple exploration-exploitation strategy. It doesn't consider user context, just learns which destinations are generally popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33d9e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéØ EPSILON-GREEDY TRAVEL RECOMMENDER\n",
      "======================================================================\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for You:\n",
      "----------------------------------------------------------------------\n",
      "   1. V∆∞·ªùn qu·ªëc gia N√∫i Ch√∫a         (tham quan      ) | Score: 0.015\n",
      "   2. Ch√πa T√¥n Th·∫°nh                 (tham quan      ) | Score: 0.011\n",
      "   3. ƒê·ªânh Qu·∫ø                       (thi√™n nhi√™n    ) | Score: -0.002\n",
      "----------------------------------------------------------------------\n",
      "‚ö†Ô∏è  No valid selection. Please try again.\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for You:\n",
      "----------------------------------------------------------------------\n",
      "   1. V∆∞·ªùn qu·ªëc gia N√∫i Ch√∫a         (tham quan      ) | Score: 0.015\n",
      "   2. Ch√πa T√¥n Th·∫°nh                 (tham quan      ) | Score: 0.011\n",
      "   3. ƒê·ªânh Qu·∫ø                       (thi√™n nhi√™n    ) | Score: -0.002\n",
      "----------------------------------------------------------------------\n",
      "‚ö†Ô∏è  No valid selection. Please try again.\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for You:\n",
      "----------------------------------------------------------------------\n",
      "   1. V∆∞·ªùn qu·ªëc gia N√∫i Ch√∫a         (tham quan      ) | Score: 0.015\n",
      "   2. Ch√πa T√¥n Th·∫°nh                 (tham quan      ) | Score: 0.011\n",
      "   3. ƒê·ªânh Qu·∫ø                       (thi√™n nhi√™n    ) | Score: -0.002\n",
      "----------------------------------------------------------------------\n",
      "‚ö†Ô∏è  No valid selection. Please try again.\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for You:\n",
      "----------------------------------------------------------------------\n",
      "   1. V∆∞·ªùn qu·ªëc gia N√∫i Ch√∫a         (tham quan      ) | Score: 0.015\n",
      "   2. Ch√πa T√¥n Th·∫°nh                 (tham quan      ) | Score: 0.011\n",
      "   3. ƒê·ªânh Qu·∫ø                       (thi√™n nhi√™n    ) | Score: -0.002\n",
      "----------------------------------------------------------------------\n",
      "‚ö†Ô∏è  No valid selection. Please try again.\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for You:\n",
      "----------------------------------------------------------------------\n",
      "   1. V∆∞·ªùn qu·ªëc gia N√∫i Ch√∫a         (tham quan      ) | Score: 0.015\n",
      "   2. Ch√πa T√¥n Th·∫°nh                 (tham quan      ) | Score: 0.011\n",
      "   3. ƒê·ªânh Qu·∫ø                       (thi√™n nhi√™n    ) | Score: -0.002\n",
      "----------------------------------------------------------------------\n",
      "‚ö†Ô∏è  No valid selection. Please try again.\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for You:\n",
      "----------------------------------------------------------------------\n",
      "   1. V∆∞·ªùn qu·ªëc gia N√∫i Ch√∫a         (tham quan      ) | Score: 0.015\n",
      "   2. Ch√πa T√¥n Th·∫°nh                 (tham quan      ) | Score: 0.011\n",
      "   3. ƒê·ªânh Qu·∫ø                       (thi√™n nhi√™n    ) | Score: -0.002\n",
      "----------------------------------------------------------------------\n",
      "‚ö†Ô∏è  No valid selection. Please try again.\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for You:\n",
      "----------------------------------------------------------------------\n",
      "   1. V∆∞·ªùn qu·ªëc gia N√∫i Ch√∫a         (tham quan      ) | Score: 0.015\n",
      "   2. Ch√πa T√¥n Th·∫°nh                 (tham quan      ) | Score: 0.011\n",
      "   3. ƒê·ªânh Qu·∫ø                       (thi√™n nhi√™n    ) | Score: -0.002\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üëã Thank you for using the Travel Recommender!\n",
      "\n",
      "üëã Thank you for using the Travel Recommender!\n"
     ]
    }
   ],
   "source": [
    "# Run Epsilon-Greedy Interactive Demo\n",
    "interactive_recommendation_egreedy(agent_egreedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee10240",
   "metadata": {},
   "source": [
    "### Demo 2: LinUCB (Contextual Bandit)\n",
    "\n",
    "This model considers user preferences to provide personalized recommendations. It uses confidence bounds to balance exploration and exploitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363dcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LinUCB Interactive Demo\n",
    "interactive_recommendation_linucb(agent_linucb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc6899",
   "metadata": {},
   "source": [
    "### Demo 3: Thompson Sampling\n",
    "\n",
    "This model uses Bayesian inference to learn user preferences. It naturally balances exploration and exploitation through probability matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f75b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéØ THOMPSON SAMPLING TRAVEL RECOMMENDER\n",
      "======================================================================\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for User 2:\n",
      "----------------------------------------------------------------------\n",
      "   1. S√¥ng Ch√†y                      (tham quan      ) | Score: 0.215\n",
      "   2. C·ª≠a kh·∫©u H·ªØu Ngh·ªã              (tham quan      ) | Score: 0.109\n",
      "   3. ƒê·ªÅn Tr·∫ßn Th∆∞∆°ng                (kh√°m ph√°       ) | Score: 0.066\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚úàÔ∏è  Top 3 Recommendations for User 2:\n",
      "----------------------------------------------------------------------\n",
      "   1. S√¥ng Ch√†y                      (tham quan      ) | Score: 0.215\n",
      "   2. C·ª≠a kh·∫©u H·ªØu Ngh·ªã              (tham quan      ) | Score: 0.109\n",
      "   3. ƒê·ªÅn Tr·∫ßn Th∆∞∆°ng                (kh√°m ph√°       ) | Score: 0.066\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run Thompson Sampling Interactive Demo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43minteractive_recommendation_ts\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_ts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36minteractive_recommendation_ts\u001b[39m\u001b[34m(agent)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Get clicks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m clicks = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43müëÜ Click on recommendation (1-3) or \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m to quit: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clicks.lower() == \u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müëã Thank you for using the Travel Recommender!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/adaptive-RL/lib/python3.11/site-packages/ipykernel/kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/adaptive-RL/lib/python3.11/site-packages/ipykernel/kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Run Thompson Sampling Interactive Demo\n",
    "interactive_recommendation_ts(agent_ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive-RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
